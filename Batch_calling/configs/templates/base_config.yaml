# Experiment Configuration
experiment:
  date: {date}  # YYYY-MM-DD
  time: {time}  # HHMM
  description: {description}

# User Configuration
users:
  user_ids: {user_ids}  # List of user IDs
  user_names: {user_names}  # Optional username

# API Configuration
api:
  groq:
    model: "deepseek-r1-distill-llama-70b" # "llama-3.3-70b-versatile"
    temperature: 0 # [0, 2]

# Data Configuration
data:
  collection_name: "Breitbart"
  batch_size: 100  # set to "all" if you want all Data in the Batch
  # sampling_method: "time_based"  

# Context Options
context:
  include_article_body: false
  include_parent_comment: true
  include_oldest_comment: true
  include_most_liked_comment: true 

# Directory Structure
paths:
  base_dir: "data"
  batch_files: "data/batch_files"
  results: "data/results"

# Prompt Configuration
prompts:
  type: "{prompt_type}"  # open_target, closed_target
  system_prompt: "{system_prompt}"  # Will be loaded from system_prompt.txt
  prompt_template: "{prompt_template}"  # Will be loaded from the appropriate template file
  targets: "{targets}"  # Will be populated from targets.py when type is closed_target
